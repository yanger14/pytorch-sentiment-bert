"""
baseline_tf_idf.py
ä½¿ç”¨ TF-IDF + Logistic Regression åœ¨ IMDB æ•°æ®é›†ä¸Šåšæƒ…æ„Ÿåˆ†æ baseline
"""

from datasets import load_dataset
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


def load_imdb_subset(n_samples: int = 10000):

    print("ğŸ”„ Loading IMDB dataset from HuggingFace...")
    dataset = load_dataset("imdb")  # ä¼šè‡ªåŠ¨ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜

    # å–ä¸€éƒ¨åˆ† train + ä¸€éƒ¨åˆ† testï¼Œåˆåœ¨ä¸€èµ·å†åˆ‡åˆ†
    train_data = dataset["train"].shuffle(seed=42).select(range(min(n_samples, len(dataset["train"]))))
    test_data = dataset["test"].shuffle(seed=42).select(range(min(n_samples // 2, len(dataset["test"]))))

    texts = list(train_data["text"]) + list(test_data["text"])
    labels = list(train_data["label"]) + list(test_data["label"])

    df = pd.DataFrame({"text": texts, "label": labels})
    print(f"âœ… Loaded {len(df)} samples.")
    return df


def build_tfidf_features(train_texts, val_texts, max_features: int = 20000):
    """
    ä½¿ç”¨ TF-IDF æŠŠæ–‡æœ¬è½¬æ¢æˆç¨€ç–å‘é‡
    """
    print("ğŸ”§ Fitting TF-IDF vectorizer...")
    vectorizer = TfidfVectorizer(
        max_features=max_features,
        ngram_range=(1, 2),   # ä½¿ç”¨ 1-gram + 2-gram
        stop_words="english"
    )
    X_train = vectorizer.fit_transform(train_texts)
    X_val = vectorizer.transform(val_texts)
    print(f"âœ… TF-IDF features shape: {X_train.shape}")
    return X_train, X_val, vectorizer


def train_logistic_regression(X_train, y_train, C: float = 2.0):
    """
    è®­ç»ƒä¸€ä¸ªé€»è¾‘å›å½’åˆ†ç±»å™¨
    """
    print("ğŸš€ Training Logistic Regression baseline...")
    clf = LogisticRegression(
        C=C,
        max_iter=1000,
        n_jobs=-1,
        solver="lbfgs"
    )
    clf.fit(X_train, y_train)
    print("âœ… Training finished.")
    return clf


def main():
    # 1. åŠ è½½æ•°æ®
    df = load_imdb_subset(n_samples=12000)

    # 2. åˆ‡åˆ†è®­ç»ƒ / éªŒè¯é›†
    train_texts, val_texts, train_labels, val_labels = train_test_split(
        df["text"],
        df["label"],
        test_size=0.2,
        random_state=42,
        stratify=df["label"]
    )
    print(f"Train size: {len(train_texts)}, Val size: {len(val_texts)}")

    # 3. TF-IDF ç‰¹å¾
    X_train, X_val, vectorizer = build_tfidf_features(train_texts, val_texts, max_features=20000)

    # 4. è®­ç»ƒé€»è¾‘å›å½’xi
    clf = train_logistic_regression(X_train, train_labels, C=2.0)

    # 5. åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    print("ğŸ“ˆ Evaluating on validation set...")
    val_preds = clf.predict(X_val)
    acc = accuracy_score(val_labels, val_preds)
    print(f"\nâ­ Baseline Accuracy: {acc * 100:.2f}%\n")

    print("Classification report:")
    print(classification_report(val_labels, val_preds, target_names=["negative", "positive"]))

    print("Confusion matrix:")
    print(confusion_matrix(val_labels, val_preds))


if __name__ == "__main__":
    main()
